# -*- coding: utf-8 -*-
import sys
import io
# Force UTF-8 output to avoid UnicodeEncodeError on Windows cp1252 terminals
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

"""
VeriResume Python AI Microservice
Flask API server that provides AI-powered resume analysis services
to the Node.js backend.

Endpoints:
- POST /api/parse-resume - Extract text and information from resume
- POST /api/analyze-resume - Get ATS score, enhancement suggestions
- POST /api/detect-fraud - Check for fraud indicators and duplicates
- POST /api/detect-anomalies - Check for anomaly indicators and duplicates (alias for detect-fraud)
- POST /api/rank-resumes - Rank multiple resumes against job description
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import sys
import traceback
from datetime import datetime
import base64
import tempfile
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Import our AI modules
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from modules.resume_parser import ResumeParser
from modules.anomaly_detector import AnomalyDetector
from modules.deep_analyzer import DeepResumeAnalyzer

# Try Groq first (FREE & FAST), then OpenAI, then Gemini
ai_analyzer = None

# Try OpenAI first (most stable)
try:
    from modules.ai_analyzer import AIAnalyzer
    ai_analyzer = AIAnalyzer()
    print("[OK] Using OpenAI GPT-4o-mini for AI analysis")
except Exception as e2:
    print(f"[WARNING] OpenAI initialization failed: {str(e2)}")
    
    # Try Groq as fallback
    if not ai_analyzer:
        try:
            from modules.groq_analyzer import GroqAnalyzer
            ai_analyzer = GroqAnalyzer()
            print("[OK] Using Groq (Llama 3.3) for AI analysis - FREE & FAST!")
            print(f"DEBUG: AI Analyzer type: {type(ai_analyzer).__name__}")
            print(f"DEBUG: Has analyze_resume method: {hasattr(ai_analyzer, 'analyze_resume')}")
        except Exception as e:
            print(f"[WARNING] Groq initialization failed: {str(e)}")
            
            # Fallback to Gemini
            if not ai_analyzer:
                try:
                    from modules.gemini_analyzer import GeminiAnalyzer
                    ai_analyzer = GeminiAnalyzer()
                    print("[OK] Using Google Gemini as fallback for AI analysis")
                except Exception as e3:
                    print(f"[ERROR] All AI providers failed (OpenAI, Groq, Gemini): {str(e3)}")
                    print("[WARNING] AI analysis features will be disabled")
                    ai_analyzer = None

# Optional modules (make imports non-blocking)
try:
    from modules.fraud_detection import FraudDetector
    fraud_detector = None  # Will initialize later
except ImportError:
    print("Warning: fraud_detection module not fully functional (missing dependencies)")
    FraudDetector = None
    fraud_detector = None

# Import Job API Scraper (Remotive + Jobicy + Arbeitnow + USAJobs ‚Äî FREE APIs, no browser)
try:
    from modules.job_api_scraper import JobAPIScraper
    job_api_scraper = JobAPIScraper()
    print("[OK] Job API Scraper initialized (Remotive + Jobicy + Arbeitnow + USAJobs)")
except Exception as e:
    print(f"[WARNING] Job API Scraper failed: {e}")
    job_api_scraper = None

# Import Fast HTTP Job Scraper (fallback for local scraping)
try:
    from modules.job_scraper_fast import FastJobScraper
    job_scraper = FastJobScraper()
    print("[OK] Fast HTTP job scraper initialized (no browser needed)")
except ImportError as e:
    print(f"[WARNING] Fast job scraper import failed: {e}")
    # Fallback to old Selenium scraper
    try:
        from modules.job_scraper import JobScraper
        job_scraper = JobScraper(headless=True)
        print("[OK] Fallback: Selenium job scraper initialized")
    except Exception as e2:
        print(f"[WARNING] Both scrapers failed: {e2}")
        job_scraper = None
except Exception as e:
    print(f"[WARNING] Job scraper setup failed: {e}")
    job_scraper = None

# Import Job Matcher (NLP-based resume-to-job matching)
try:
    from modules.job_matcher import JobMatcher, job_matcher
    print("[OK] Job Matcher (NLP + Semantic) initialized successfully")
except ImportError as e:
    print(f"[WARNING] Job Matcher import failed: {e}")
    job_matcher = None
except Exception as e:
    print(f"[WARNING] Job Matcher setup failed: {e}")
    job_matcher = None

try:
    # Temporarily disabled - sentence_transformers import hangs on Windows
    # from modules.ranking_engine import RankingEngine
    RankingEngine = None
    ranking_engine = None
    print("[INFO] Ranking engine disabled (use AI-based ranking instead)")
except ImportError:
    print("Warning: ranking_engine module not fully functional (missing dependencies)")
    RankingEngine = None
    ranking_engine = None

# Import ENHANCED HR System module (from HRcode_INTEGRATED.py)
print("\n" + "=" * 70)
print("[INIT] INITIALIZING ENHANCED VERIRESUME HR SYSTEM")
print("=" * 70)
print("[INFO] NEW FEATURES:")
print("   - Missing contact info detection (HIGH anomaly)")
print("   - Match threshold filtering")
print("   - 18 types of anomaly checks")
print("   - Smart decision logic (shortlist/review/reject)")
print("   - Groq API semantic matching")
print("-" * 70)

try:
    from modules.hr_system_enhanced import HRSystem
    hr_system = HRSystem()
    print(f"[OK] Enhanced HR System initialized successfully")
    print("-" * 70)
    print("[OK] SYSTEM READY - Advanced screening enabled!")
    print("[INFO] Note: First resume screening will take longer (AI model loading)")
    print("=" * 70 + "\n")
except Exception as e:
    print(f"[WARNING] Enhanced HR System initialization failed: {e}")
    print("[INFO] Falling back to basic HR system...")
    import traceback
    traceback.print_exc()
    try:
        from modules.hr_system import HRSystem
        hr_system = HRSystem()
        print(f"[OK] Basic HR System initialized")
    except:
        HRSystem = None
        hr_system = None
    print("=" * 70 + "\n")

# Import HRCode Service for exact HRcode_INTEGRATED.py logic
print("\n" + "=" * 70)
print("üîß INITIALIZING HRCODE SERVICE (Direct HRcode_INTEGRATED.py)")
print("=" * 70)
try:
    from hrcode_service import init_hrcode_service, get_hrcode_service
    if init_hrcode_service():
        print("‚úÖ HRCode Service initialized - Using exact HRcode_INTEGRATED.py logic")
    else:
        print("‚ö†Ô∏è  HRCode Service initialization returned False")
except Exception as e:
    print(f"‚ùå Failed to import HRCode service: {e}")
    import traceback
    traceback.print_exc()
    print("   (Fallback to standard HR system)")
print("=" * 70 + "\n")

app = Flask(__name__)
CORS(app)  # Enable CORS for Node.js backend

# Initialize modules
resume_parser = ResumeParser()
anomaly_detector_module = AnomalyDetector()
deep_analyzer = DeepResumeAnalyzer()
# ai_analyzer is already initialized above with fallback logic

# Initialize optional modules only if available
if FraudDetector:
    try:
        fraud_detector = FraudDetector()
        print("[OK] Fraud detector initialized")
    except Exception as e:
        print(f"[WARNING] Fraud detector failed: {e}")
        fraud_detector = None
else:
    fraud_detector = None
        
if RankingEngine:
    try:
        ranking_engine = RankingEngine()
        print("[OK] Ranking engine initialized")
    except Exception as e:
        print(f"[WARNING] Ranking engine failed: {e}")
        ranking_engine = None
else:
    ranking_engine = None

# Configuration
UPLOAD_FOLDER = 'uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)


@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    try:
        return jsonify({
            'status': 'healthy',
            'service': 'VeriResume Python AI Service',
            'timestamp': datetime.now().isoformat(),
            'ai_provider': 'Groq (Llama 3.3)' if ai_analyzer else 'None',
            'hr_system_ready': hr_system is not None
        })
    except Exception as e:
        print(f"Error in health check: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/model-status', methods=['GET'])
def model_status():
    """Check if AI models are loaded and ready"""
    try:
        sentence_model_loaded = False
        if hr_system:
            sentence_model_loaded = hr_system.analyzer.sentence_model is not None
        
        return jsonify({
            'status': 'ready',
            'models': {
                'hr_system': hr_system is not None,
                'ai_analyzer': ai_analyzer is not None,
                'sentence_transformer': sentence_model_loaded,
                'lazy_loading': not sentence_model_loaded
            },
            'message': 'System ready. AI model will load on first use.' if not sentence_model_loaded else 'All AI models loaded and ready'
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': 'Error checking model status',
            'error': str(e)
        }), 500


@app.route('/api/filter-tech-keywords', methods=['POST'])
def filter_tech_keywords():
    """
    Filter keywords to only keep tech/IT-related ones using Groq AI.
    
    Request JSON:
    { "keywords": ["Python", "Machine Learning", "esport", "hobbies", "React", ...] }
    
    Response:
    { "success": true, "tech_keywords": ["Python", "Machine Learning", "React", ...] }
    """
    try:
        data = request.get_json()
        keywords = data.get('keywords', [])
        
        if not keywords:
            return jsonify({'success': True, 'tech_keywords': []})
        
        # ‚îÄ‚îÄ First pass: use the TECH_SKILLS + SOFT_SKILLS sets from deep_analyzer ‚îÄ‚îÄ
        from modules.deep_analyzer import TECH_SKILLS, SOFT_SKILLS
        
        known_tech = set()
        unknown = []
        
        for kw in keywords:
            kw_lower = kw.strip().lower()
            if kw_lower in TECH_SKILLS or kw_lower in SOFT_SKILLS:
                known_tech.add(kw)
            elif len(kw_lower) < 2:
                continue  # skip garbage
            else:
                unknown.append(kw)
        
        # ‚îÄ‚îÄ Second pass: use Groq AI to classify unknown keywords ‚îÄ‚îÄ
        ai_classified_tech = []
        if unknown:
            groq_key = os.getenv('GROQ_API_KEY')
            if groq_key:
                try:
                    from groq import Groq
                    client = Groq(api_key=groq_key)
                    
                    kw_list = ', '.join(f'"{k}"' for k in unknown[:30])  # limit to 30
                    
                    response = client.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[{
                            "role": "user",
                            "content": f"""You are an expert at classifying keywords. Given this list of keywords, return ONLY the ones related to tech, IT, software, data, engineering, or professional skills. Remove hobbies, sports, personal interests, generic words.

Keywords: [{kw_list}]

Return ONLY a JSON array of the tech-related keywords, nothing else. Example: ["Python", "AWS", "Data Analysis"]
If none are tech-related, return: []"""
                        }],
                        temperature=0.1,
                        max_tokens=500,
                    )
                    
                    result_text = response.choices[0].message.content.strip()
                    # Parse JSON array from response
                    import json
                    # Try to extract JSON array
                    if '[' in result_text:
                        json_str = result_text[result_text.index('['):result_text.rindex(']')+1]
                        ai_classified_tech = json.loads(json_str)
                    
                    print(f"[FILTER-KEYWORDS] Groq classified {len(ai_classified_tech)} of {len(unknown)} unknown keywords as tech")
                except Exception as e:
                    print(f"[FILTER-KEYWORDS] Groq classification failed: {e}")
                    # Fallback: keep keywords that look technical (contain numbers, dots, or are in camelCase)
                    import re
                    for kw in unknown:
                        if re.search(r'[A-Z][a-z]+[A-Z]|\.|\+\+|#|\d', kw) or len(kw) <= 4:
                            ai_classified_tech.append(kw)
            else:
                # No Groq key - use pattern matching fallback
                import re
                for kw in unknown:
                    kw_lower = kw.lower()
                    # Keep if it looks like a tech term
                    tech_patterns = [
                        r'develop', r'engineer', r'analy', r'design', r'program',
                        r'code', r'web', r'mobile', r'cloud', r'server', r'database',
                        r'network', r'security', r'devops', r'api', r'framework',
                        r'library', r'tool', r'system', r'software', r'hardware',
                        r'test', r'debug', r'deploy', r'architect', r'full.?stack',
                        r'front.?end', r'back.?end', r'data', r'machine', r'deep',
                        r'artificial', r'neural', r'model', r'algorithm',
                    ]
                    if any(re.search(p, kw_lower) for p in tech_patterns):
                        ai_classified_tech.append(kw)
        
        # Combine known + AI-classified
        all_tech = list(known_tech) + ai_classified_tech
        
        # Preserve original order from input
        ordered_tech = [kw for kw in keywords if kw in all_tech]
        
        print(f"[FILTER-KEYWORDS] Input: {len(keywords)} keywords -> Output: {len(ordered_tech)} tech keywords")
        
        return jsonify({
            'success': True,
            'tech_keywords': ordered_tech,
            'filtered_out': [kw for kw in keywords if kw not in all_tech],
            'total_input': len(keywords),
            'total_tech': len(ordered_tech),
        })
        
    except Exception as e:
        print(f"[FILTER-KEYWORDS] Error: {e}")
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/parse-resume', methods=['POST'])
def parse_resume():
    """
    Parse resume and extract structured information
    
    Request:
    - file: Resume file (PDF/DOCX)
    OR
    - fileData: Base64 encoded file data
    - fileName: Original file name
    
    Response:
    {
        "success": true,
        "data": {
            "name": "John Doe",
            "email": "john@example.com",
            "phone": "+92-300-1234567",
            "education": [...],
            "experience": [...],
            "skills": [...],
            "summary": "...",
            "rawText": "..."
        }
    }
    """
    try:
        # Handle file upload
        if 'file' in request.files:
            file = request.files['file']
            if file.filename == '':
                return jsonify({'success': False, 'error': 'No file selected'}), 400
            
            print(f"\n[PARSE-RESUME] Parsing file: {file.filename}")
            
            # Save file temporarily
            file_path = os.path.join(UPLOAD_FOLDER, file.filename)
            file.save(file_path)
            print(f"[PARSE-RESUME] File saved to: {file_path}")
        
        elif 'fileData' in request.json:
            # Handle base64 encoded file
            file_name = request.json.get('fileName', 'resume.pdf')
            print(f"\n[PARSE-RESUME] Parsing base64 file: {file_name}")
            
            file_data = base64.b64decode(request.json['fileData'])
            
            file_path = os.path.join(UPLOAD_FOLDER, file_name)
            with open(file_path, 'wb') as f:
                f.write(file_data)
            print(f"[PARSE-RESUME] File written to: {file_path}")
        
        else:
            print("[PARSE-RESUME] ‚ùå No file provided in request")
            return jsonify({'success': False, 'error': 'No file provided'}), 400
        
        # Parse resume
        print("[PARSE-RESUME] Parsing resume using resume_parser...")
        parsed_data = resume_parser.parse_resume(file_path)
        
        print(f"[PARSE-RESUME] ‚úÖ Resume parsed successfully")
        print(f"   Name: {parsed_data.get('name', 'Unknown')}")
        print(f"   Email: {parsed_data.get('email', 'None')}")
        print(f"   Phone: {parsed_data.get('phone', 'None')}")
        print(f"   Skills: {len(parsed_data.get('skills', []))} found")
        print(f"   Experience: {len(parsed_data.get('experience', []))} entries")
        print(f"   Education: {len(parsed_data.get('education', []))} entries")
        
        # Clean up temp file
        if os.path.exists(file_path):
            os.remove(file_path)
            print(f"[PARSE-RESUME] Temp file cleaned up")
        
        return jsonify({
            'success': True,
            'data': parsed_data
        })
    
    except Exception as e:
        print(f"\n‚ùå ERROR parsing resume: {str(e)}")
        print(f"   Exception type: {type(e).__name__}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'type': type(e).__name__
        }), 500


@app.route('/api/analyze-resume', methods=['POST'])
def analyze_resume():
    """
    Analyze resume using EXACT HRcode_INTEGRATED.py logic for accurate ATS scoring
    
    Request:
    {
        "resumeText": "...",
        "jobDescription": "...",
        "anomalyThreshold": 30,
        "matchThreshold": 50
    }
    
    Response:
    {
        "success": true,
        "data": {
            "ats_score": 75,
            "matchedSkills": [...],
            "missingSkills": [...],
            "anomalies": {...},
            "anomalyWeight": 25,
            "decision": "SHORTLISTED"
        }
    }
    """
    try:
        data = request.json
        resume_text = data.get('resumeText', '')
        job_description = data.get('jobDescription', '')
        parsed_skills = data.get('parsedSkills', [])  # Pre-parsed skills from caller
        anomaly_threshold = data.get('anomalyThreshold', 30)
        match_threshold = data.get('matchThreshold', 50)
        
        print(f"[ANALYZE-RESUME] Resume={len(resume_text)} chars, JD={bool(job_description)}, PreParsedSkills={len(parsed_skills)}")
        
        if not resume_text:
            return jsonify({'success': False, 'error': 'Resume text is required'}), 400
        
        if not job_description:
            job_description = 'Professional position requiring relevant skills and experience'
        
        # Try HRCode service first
        hrcode_svc = get_hrcode_service()
        result = None
        
        if hrcode_svc:
            try:
                result = hrcode_svc.analyze_resume_complete(resume_text, job_description, anomaly_threshold, match_threshold)
                if not result.get('success'):
                    result = None
            except Exception as e:
                print(f"[ANALYZE-RESUME] HRCode failed: {str(e)}")
                result = None
        
        # If HRCode failed, use Deep Analyzer + Groq AI for intelligent matching
        if not result or not result.get('success'):
            # Use DeepResumeAnalyzer for structural scoring
            deep_result = deep_analyzer.analyze(resume_text, job_description)
            
            # Use pre-parsed skills if available, otherwise extract
            if parsed_skills and len(parsed_skills) > 0:
                extracted_skills = parsed_skills
            else:
                try:
                    parsed_data = resume_parser.parse_resume(resume_text)
                    extracted_skills = parsed_data.get('skills', [])
                except:
                    extracted_skills = []
            
            # Merge skills (deduplicate)
            all_skills = list(set(extracted_skills + deep_result.get('extracted_skills', [])))
            
            # ‚îÄ‚îÄ Groq AI-Powered Skill Matching ‚îÄ‚îÄ
            ai_matched = []
            ai_missing = []
            ai_match_score = 0
            ai_recommendation = ''
            
            groq_key = os.getenv('GROQ_API_KEY')
            if groq_key and job_description and len(job_description) > 20:
                try:
                    from groq import Groq
                    import json
                    client = Groq(api_key=groq_key)
                    
                    skills_str = ', '.join(f'"{s}"' for s in all_skills[:30])
                    
                    response = client.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[{
                            "role": "user",
                            "content": f"""You are an expert HR recruiter. Analyze this resume against the job description.

JOB DESCRIPTION:
{job_description[:2000]}

CANDIDATE SKILLS: [{skills_str}]

RESUME SUMMARY (first 1500 chars):
{resume_text[:1500]}

Return a JSON object with:
{{
  "match_score": <0-100 how well the candidate fits>,
  "matched_skills": [<skills from candidate that match job requirements>],
  "missing_skills": [<important skills from JD that candidate lacks>],
  "recommendation": "<1-2 sentence hiring recommendation>",
  "strengths": [<top 3 strengths>],
  "concerns": [<top 3 concerns if any>]
}}

Return ONLY the JSON object, nothing else."""
                        }],
                        temperature=0.2,
                        max_tokens=800,
                    )
                    
                    ai_text = response.choices[0].message.content.strip()
                    if '{' in ai_text:
                        json_str = ai_text[ai_text.index('{'):ai_text.rindex('}')+1]
                        ai_result = json.loads(json_str)
                        ai_matched = ai_result.get('matched_skills', [])
                        ai_missing = ai_result.get('missing_skills', [])
                        ai_match_score = ai_result.get('match_score', 0)
                        ai_recommendation = ai_result.get('recommendation', '')
                        ai_strengths = ai_result.get('strengths', [])
                        ai_concerns = ai_result.get('concerns', [])
                        print(f"[ANALYZE-RESUME] Groq AI: match={ai_match_score}%, matched={len(ai_matched)}, missing={len(ai_missing)}")
                except Exception as e:
                    print(f"[ANALYZE-RESUME] Groq AI matching failed: {e}")
                    ai_strengths = []
                    ai_concerns = []
            else:
                ai_strengths = []
                ai_concerns = []
            
            # Use AI match score if available, otherwise calculate from skills
            if ai_match_score > 0:
                match_score = ai_match_score
                matched_skills = ai_matched
                missing_skills = ai_missing
            else:
                matched_skills = deep_result.get('matched_skills', all_skills[:8])
                missing_skills = deep_result.get('missing_skills', [])
                match_score = min(60 + len(all_skills) * 4, 95)
            
            grammar_score = deep_result.get('grammar_score', 70)
            readability_score = deep_result.get('readability_score', 70)
            structure_score = deep_result.get('structure_score', 70)
            base_ats = deep_result.get('ats_score', 70)
            
            # Enhanced ATS: blend structural ATS with AI match score for accuracy
            if ai_match_score > 0:
                ats_score = round(base_ats * 0.4 + ai_match_score * 0.6)
            else:
                ats_score = base_ats
            
            overall_score = deep_result.get('overall_score', 70)
            
            # Combine weaknesses from deep analysis + AI concerns
            weaknesses = deep_result.get('weaknesses', [])
            if ai_concerns:
                weaknesses = ai_concerns + weaknesses
            
            # Combine suggestions from deep analysis + AI strengths context
            suggestions = deep_result.get('suggestions', [])
            
            result = {
                'success': True,
                'ats_score': ats_score,
                'grammar_score': grammar_score,
                'readability_score': readability_score,
                'structure_score': structure_score,
                'overall_score': overall_score,
                'match_score': match_score,
                'quality_score': min(70 + len(all_skills) * 2, 90),
                'decision': 'SHORTLISTED' if ats_score >= 70 else 'NEEDS_REVIEW',
                'shortlisted': ats_score >= 70,
                'reason': ai_recommendation or f'Resume shows background with {len(all_skills)} skills',
                'recommendation': ai_recommendation or ('Recommended for interview' if ats_score >= 70 else 'Review manually'),
                'anomaly_weight': 0,
                'anomaly_count': 0,
                'anomaly_severity': 'none',
                'candidate_info': {'name': 'Resume Candidate'},
                'matched_skills': matched_skills,
                'missing_skills': missing_skills,
                'skills': all_skills,
                'recommended_keywords': deep_result.get('recommended_keywords', []),
                'tech_skills': deep_result.get('tech_skills', []),
                'soft_skills': deep_result.get('soft_skills', []),
                'weaknesses': weaknesses[:10],
                'suggestions': suggestions[:10],
                'section_analysis': deep_result.get('section_analysis', {}),
                'metrics': deep_result.get('metrics', {}),
                'education': [],
                'experience': []
            }
        
        # Handle anomalies - can be dict or list of objects
        anomalies = result.get('anomalies', {})
        weaknesses = []
        
        if isinstance(anomalies, list):
            # If it's a list of dicts with 'message' field, extract messages
            for item in anomalies:
                if isinstance(item, dict) and 'message' in item:
                    weaknesses.append(item['message'])
                elif isinstance(item, str):
                    weaknesses.append(item)
        elif isinstance(anomalies, dict):
            # If it's a dict, get values
            for key, value in anomalies.items():
                if isinstance(value, dict) and 'message' in value:
                    weaknesses.append(value['message'])
                elif isinstance(value, str):
                    weaknesses.append(value)
                else:
                    weaknesses.append(str(value))
        
        # Transform result to API format
        analysis = {
            'ats_score': result.get('ats_score', 70),
            'match_score': result.get('match_score', 60),
            'quality_score': result.get('quality_score', 75),
            'keyword_density': 65,
            'grammar_score': result.get('grammar_score', 70),
            'readability_score': result.get('readability_score', 70),
            'structure_score': result.get('structure_score', 70),
            'overall_score': result.get('overall_score', 70),
            'weaknesses': result.get('weaknesses', weaknesses),
            'suggestions': result.get('suggestions', ['Add more specific metrics and achievements', 'Use action verbs to describe accomplishments']),
            'enhanced_summary': '',
            'decision_status': result.get('decision'),
            'shortlisted': result.get('shortlisted'),
            'reason': result.get('reason'),
            'recommendation': result.get('recommendation'),
            'anomaly_weight': result.get('anomaly_weight', 0),
            'anomaly_count': result.get('anomaly_count', 0),
            'anomaly_severity': result.get('anomaly_severity', 'none'),
            'anomalies': anomalies,
            'matchedSkills': result.get('matched_skills', []),
            'missingSkills': result.get('missing_skills', []),
            'candidateName': result.get('candidate_info', {}).get('name'),
            'skills': result.get('skills', []),
            'recommended_keywords': result.get('recommended_keywords', []),
            'tech_skills': result.get('tech_skills', []),
            'soft_skills': result.get('soft_skills', []),
            'section_analysis': result.get('section_analysis', {}),
            'metrics': result.get('metrics', {}),
            'education': result.get('education', []),
            'experience': result.get('experience', [])
        }
        
        print(f"[ANALYZE-RESUME] Done: ATS={analysis['ats_score']}%, Match={analysis['match_score']}%, Decision={analysis['decision_status']}")
        
        return jsonify({
            'success': True,
            'data': analysis
        })
    
    except Exception as e:
        print(f"\n‚ùå ERROR analyzing resume: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/detect-fraud', methods=['POST'])
def detect_fraud():
    """
    Detect fraud indicators in resume
    
    Request:
    {
        "resumeData": {
            "name": "...",
            "email": "...",
            "phone": "...",
            "education": [...],
            "experience": [...],
            "skills": [...]
        },
        "resumeText": "...",
        "existingResumes": [] (optional, for duplicate detection)
    }
    
    Response:
    {
        "success": true,
        "data": {
            "riskScore": 25,
            "riskLevel": "Low",
            "indicators": [...],
            "duplicates": [...],
            "recommendations": [...]
        }
    }
    """
    try:
        data = request.json
        resume_data = data.get('resumeData', {})
        resume_text = data.get('resumeText', '')
        existing_resumes = data.get('existingResumes', [])
        
        print(f"\n[DETECT-FRAUD] Request received")
        print(f"   Resume data keys: {list(resume_data.keys())}")
        print(f"   Resume text length: {len(resume_text)} chars")
        print(f"   Name: {resume_data.get('name', 'Unknown')}")
        print(f"   Email: {resume_data.get('email', 'None')}")
        
        if not resume_data:
            return jsonify({'success': False, 'error': 'Resume data is required'}), 400
        
        # Use HR System fraud detection if available (CORE SOLUTION)
        if hr_system:
            print("[DETECT-FRAUD] Using HR System anomaly_detector for fraud detection")
            try:
                print("[DETECT-FRAUD] Calling anomaly_detector.detect_anomalies...")
                fraud_report = hr_system.anomaly_detector.detect_anomalies(resume_data)
                print(f"[DETECT-FRAUD] ‚úÖ Anomaly detection complete")
                print(f"   Risk level: {fraud_report.get('risk_level', 'Unknown') if isinstance(fraud_report, dict) else 'Unknown'}")
                print(f"   Anomalies: {len(fraud_report.get('anomalies', [])) if isinstance(fraud_report, dict) else 0}")
                
                # Convert HR System format to expected format
                fraud_result = {
                    'risk_score': fraud_report.get('fraud_score', 0) if isinstance(fraud_report, dict) else 0,
                    'risk_level': fraud_report.get('risk_level', 'Low') if isinstance(fraud_report, dict) else 'Unknown',
                    'indicators': fraud_report.get('issues', []) if isinstance(fraud_report, dict) else [],
                    'duplicates': [],  # Not implemented in HR system yet
                    'recommendations': []
                }
            except Exception as e:
                print(f"[DETECT-FRAUD] ‚ö†Ô∏è HR System fraud detection failed: {e}")
                import traceback
                traceback.print_exc()
                fraud_result = {
                    'risk_score': 0,
                    'risk_level': 'Unknown',
                    'indicators': [str(e)],
                    'duplicates': [],
                    'recommendations': []
                }
        elif fraud_detector:
            print("[DETECT-FRAUD] Using legacy fraud detector")
            fraud_result = fraud_detector.check_resume(resume_data, resume_text, existing_resumes)
        else:
            # Fallback: Basic fraud check
            print("[DETECT-FRAUD] ‚ö†Ô∏è No fraud detector available, using basic check")
            fraud_result = {
                'risk_score': 0,
                'risk_level': 'Unknown',
                'indicators': ['Fraud detection service not available'],
                'duplicates': [],
                'recommendations': ['Enable fraud detection module for detailed analysis']
            }
        
        print(f"[DETECT-FRAUD] ‚úÖ Returning result - Risk Level: {fraud_result.get('risk_level', 'Unknown')}")
        return jsonify({
            'success': True,
            'data': fraud_result
        })
    
    except Exception as e:
        print(f"\n‚ùå ERROR detecting fraud: {str(e)}")
        print(f"   Exception type: {type(e).__name__}")
        print(f"   Resume data keys: {list(resume_data.keys()) if resume_data else 'Empty'}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'type': type(e).__name__,
            'details': traceback.format_exc() if os.getenv('DEBUG') else None
        }), 500


@app.route('/api/detect-anomalies', methods=['POST'])
def detect_anomalies():
    """
    Detect anomalies in resume (new naming convention)
    This is an alias for /api/detect-fraud for terminology consistency
    
    Request:
    {
        "resumeData": {
            "name": "...",
            "email": "...",
            "phone": "...",
            "education": [...],
            "experience": [...],
            "skills": [...]
        },
        "resumeText": "...",
        "existingResumes": [] (optional, for duplicate detection)
    }
    
    Response:
    {
        "success": true,
        "data": {
            "riskScore": 25,
            "riskLevel": "Low",
            "indicators": [...],
            "duplicates": [...],
            "recommendations": [...]
        }
    }
    """
    # Delegate to detect_fraud - same implementation with new naming
    return detect_fraud()




@app.route('/api/hr/parse-resume', methods=['POST'])
def hr_parse_resume():
    """
    HR System: Parse resume with enhanced extraction
    
    Request:
    - file: Resume file (PDF/DOCX)
    OR
    - filePath: Path to resume file
    
    Response:
    {
        "success": true,
        "data": {
            "name": "John Doe",
            "email": "john@example.com",
            "phone": "+92-300-1234567",
            "skills": [...],
            "raw_text": "..."
        }
    }
    """
    try:
        if not hr_system:
            return jsonify({
                'success': False, 
                'error': 'HR System is loading. Please wait a moment and try again.',
                'status': 'loading'
            }), 503
        
        # Handle file upload
        file_path = None
        if 'file' in request.files:
            file = request.files['file']
            if file.filename == '':
                return jsonify({'success': False, 'error': 'No file selected'}), 400
            
            file_path = os.path.join(UPLOAD_FOLDER, file.filename)
            file.save(file_path)
        elif request.json and 'filePath' in request.json:
            file_path = request.json['filePath']
        else:
            return jsonify({'success': False, 'error': 'No file provided'}), 400
        
        # Parse resume using HR system
        parsed_data = hr_system.parser.parse_resume(file_path)
        
        return jsonify({
            'success': True,
            'data': parsed_data
        })
    
    except Exception as e:
        print(f"Error in HR parse resume: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/hr/detect-fraud', methods=['POST'])
def hr_detect_fraud():
    """
    HR System: Detect fraud in resume
    
    Request:
    {
        "resumeData": {
            "name": "...",
            "email": "...",
            "skills": [...],
            ...
        }
    }
    
    Response:
    {
        "success": true,
        "data": {
            "fraud_score": 0-100,
            "risk_level": "Low/Medium/High",
            "missing_info": [...],
            "issues": [...]
        }
    }
    """
    try:
        if not hr_system:
            return jsonify({
                'success': False, 
                'error': 'HR System is loading. Please wait a moment and try again.',
                'status': 'loading'
            }), 503
        
        data = request.json
        resume_data = data.get('resumeData', {})
        
        if not resume_data:
            return jsonify({'success': False, 'error': 'Resume data required'}), 400
        
        # Detect fraud
        fraud_report = hr_system.fraud_detector.detect_fraud(resume_data)
        
        return jsonify({
            'success': True,
            'data': fraud_report
        })
    
    except Exception as e:
        print(f"Error in HR fraud detection: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/hr/analyze-resume', methods=['POST'])
def hr_analyze_resume():
    """
    HR System: Analyze resume with ATS scoring
    
    Request:
    {
        "resumeData": {...},
        "jobDescription": "..."
    }
    
    Response:
    {
        "success": true,
        "data": {
            "ats_score": 85,
            "rating": "Good",
            "feedback": [...],
            "job_match": {
                "match_percentage": 78,
                "similarity_score": 0.78
            }
        }
    }
    """
    try:
        if not hr_system:
            return jsonify({
                'success': False, 
                'error': 'HR System is loading. Please wait a moment and try again.',
                'status': 'loading'
            }), 503
        
        data = request.json
        resume_data = data.get('resumeData', {})
        job_description = data.get('jobDescription', '')
        
        if not resume_data:
            return jsonify({'success': False, 'error': 'Resume data required'}), 400
        
        # Analyze resume
        analysis = hr_system.analyzer.analyze_resume(resume_data, job_description)
        
        return jsonify({
            'success': True,
            'data': analysis
        })
    
    except Exception as e:
        print(f"Error in HR resume analysis: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/hr/process-resume', methods=['POST'])
def hr_process_resume():
    """
    HR System: Complete resume processing (parse + fraud + analyze)
    
    Request:
    - file: Resume file
    - jobDescription: Job description (optional)
    
    Response:
    {
        "success": true,
        "data": {
            "candidate_info": {...},
            "parsed_data": {...},
            "fraud_report": {...},
            "analysis": {...}
        }
    }
    """
    try:
        if not hr_system:
            return jsonify({
                'success': False, 
                'error': 'HR System is loading. Please wait a moment and try again.',
                'status': 'loading'
            }), 503
        
        # Handle file upload
        file_path = None
        if 'file' in request.files:
            file = request.files['file']
            if file.filename == '':
                return jsonify({'success': False, 'error': 'No file selected'}), 400
            
            file_path = os.path.join(UPLOAD_FOLDER, file.filename)
            file.save(file_path)
        elif request.json and 'filePath' in request.json:
            file_path = request.json['filePath']
        else:
            return jsonify({'success': False, 'error': 'No file provided'}), 400
        
        # Get job description from form or JSON
        job_description = ''
        if request.form and 'jobDescription' in request.form:
            job_description = request.form['jobDescription']
        elif request.json and 'jobDescription' in request.json:
            job_description = request.json['jobDescription']
        
        # Process resume with full HR analysis
        result = hr_system.process_resume(file_path, job_description)
        
        # Add anomaly detection to the result
        try:
            parsed_data = result.get('parsed_data', {})
            anomalies = anomaly_detector_module.detect_anomalies(parsed_data)
            anomalies['report'] = anomaly_detector_module.generate_anomaly_report(anomalies)
            result['anomaly_detection'] = anomalies
            print(f"[INFO] Anomaly detection completed: {anomalies['anomaly_count']} issues found")
        except Exception as e:
            print(f"[WARNING] Anomaly detection failed: {e}")
            result['anomaly_detection'] = {'error': str(e)}
        
        return jsonify({
            'success': True,
            'data': result
        })
    
    except Exception as e:
        print(f"Error in HR process resume: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/hr/detect-anomalies', methods=['POST'])
def hr_detect_anomalies():
    """
    HR System: Detect data quality anomalies in parsed resume
    
    Detects:
    - Languages listed as technical skills
    - Generic software listed as skills
    - Education in experience section
    - Experience in education section
    - Duplicate entries
    
    Request:
    {
        "parsedData": {
            "candidate_info": {...},
            "skills": [...],
            "education": [...],
            "experience": [...]
        }
    }
    OR
    {
        "file": <resume file>
    }
    
    Response:
    {
        "success": true,
        "data": {
            "has_anomalies": true,
            "anomaly_count": 3,
            "severity": "medium",
            "issues": [
                {
                    "type": "language_as_skill",
                    "severity": "medium",
                    "field": "skills",
                    "value": "English",
                    "message": "..."
                }
            ],
            "details": {...},
            "report": "Human-readable report"
        }
    }
    """
    try:
        parsed_data = None
        
        # Option 1: Receive already parsed data
        if request.json and 'parsedData' in request.json:
            parsed_data = request.json['parsedData']
        
        # Option 2: Parse resume file first
        elif 'file' in request.files:
            file = request.files['file']
            if file.filename == '':
                return jsonify({'success': False, 'error': 'No file selected'}), 400
            
            # Save and parse file
            file_path = os.path.join(UPLOAD_FOLDER, file.filename)
            file.save(file_path)
            
            parsed_data = resume_parser.parse_resume(file_path)
            
            # Clean up
            if os.path.exists(file_path):
                os.remove(file_path)
        
        # Option 3: Receive file path (from previous processing)
        elif request.json and 'filePath' in request.json:
            file_path = request.json['filePath']
            parsed_data = resume_parser.parse_resume(file_path)
        
        else:
            return jsonify({
                'success': False, 
                'error': 'Either parsedData or file must be provided'
            }), 400
        
        # Detect anomalies
        anomalies = anomaly_detector_module.detect_anomalies(parsed_data)
        
        # Generate human-readable report
        report = anomaly_detector_module.generate_anomaly_report(anomalies)
        anomalies['report'] = report
        
        return jsonify({
            'success': True,
            'data': anomalies
        })
    
    except Exception as e:
        print(f"Error detecting anomalies: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/hr/bulk-screen-resumes', methods=['POST'])
def hr_bulk_screen_resumes():
    """
    HR System: Process multiple resumes with anomaly filtering and ranking
    
    This endpoint:
    1. Accepts multiple resume files
    2. Extracts and parses text from each resume
    3. Detects anomalies and calculates weight
    4. Filters out resumes with anomaly weight > threshold
    5. Ranks remaining resumes by job description match
    6. Returns shortlisted and rejected candidates
    
    Request (multipart/form-data):
    - files[]: Multiple resume files
    - jobDescription: Job description text
    - requirements: Job requirements (optional)
    - anomalyThreshold: Weight threshold for rejection (default: 30)
    
    Response:
    {
        "success": true,
        "data": {
            "total_uploaded": 10,
            "shortlisted": 6,
            "rejected": 4,
            "shortlisted_candidates": [
                {
                    "rank": 1,
                    "candidate_name": "John Doe",
                    "email": "john@example.com",
                    "match_score": 85,
                    "anomaly_weight": 8,
                    "anomaly_status": "SHORTLISTED",
                    "parsed_data": {...},
                    "anomaly_detection": {...},
                    "analysis": {...}
                },
                ...
            ],
            "rejected_candidates": [
                {
                    "candidate_name": "Jane Doe",
                    "email": "jane@example.com",
                    "anomaly_weight": 45,
                    "anomaly_status": "REJECTED",
                    "rejection_reason": "Anomaly weight (45) exceeds threshold (30)",
                    "anomaly_detection": {...}
                },
                ...
            ]
        }
    }
    """
    try:
        if not hr_system:
            return jsonify({
                'success': False, 
                'error': 'HR System is loading. Please wait a moment and try again.',
                'status': 'loading'
            }), 503
        
        # Get uploaded files
        files = request.files.getlist('files[]') or request.files.getlist('files')
        if not files or len(files) == 0:
            return jsonify({
                'success': False,
                'error': 'No resume files provided. Please upload at least one resume.'
            }), 400
        
        # Get job description
        job_description = request.form.get('jobDescription', '')
        if not job_description:
            return jsonify({
                'success': False,
                'error': 'Job description is required for ranking resumes.'
            }), 400
        
        # Get requirements (optional)
        requirements = request.form.get('requirements', '')
        
        # Get anomaly threshold (default: 30)
        anomaly_threshold = int(request.form.get('anomalyThreshold', 30))
        
        print(f"\n{'='*70}")
        print(f"üîç BULK RESUME SCREENING STARTED")
        print(f"{'='*70}")
        print(f"üìÑ Resumes uploaded: {len(files)}")
        print(f"üéØ Job description provided: {len(job_description)} characters")
        print(f"‚öñÔ∏è  Anomaly threshold: {anomaly_threshold}")
        print(f"{'-'*70}\n")
        
        shortlisted_candidates = []
        rejected_candidates = []
        processing_errors = []
        
        # Process each resume
        for idx, file in enumerate(files, 1):
            try:
                print(f"[{idx}/{len(files)}] Processing: {file.filename}")
                
                # Save file temporarily
                file_path = os.path.join(UPLOAD_FOLDER, file.filename)
                file.save(file_path)
                
                # Parse resume
                parsed_data = resume_parser.parse_resume(file_path)
                candidate_name = parsed_data.get('candidate_info', {}).get('name', 'Unknown')
                candidate_email = parsed_data.get('candidate_info', {}).get('email', '')
                
                print(f"  ‚úì Parsed: {candidate_name}")
                
                # Detect anomalies
                anomalies = anomaly_detector_module.detect_anomalies(parsed_data)
                anomaly_weight = anomalies.get('weight', 0)
                
                print(f"  ‚úì Anomaly weight: {anomaly_weight}")
                
                # Check if should be shortlisted
                shortlist_decision = anomaly_detector_module.should_shortlist(
                    anomalies, 
                    threshold=anomaly_threshold
                )
                
                if shortlist_decision['shortlisted']:
                    # Calculate match score with job description
                    if hr_system:
                        ats_results = hr_system.analyzer.calculate_ats_score(
                            parsed_data, 
                            job_description
                        )
                        match_score = ats_results.get('ats_score', 0)
                    else:
                        match_score = 50  # Default if HR system unavailable
                    
                    print(f"  ‚úì Match score: {match_score}")
                    print(f"  ‚úÖ SHORTLISTED\n")
                    
                    shortlisted_candidates.append({
                        'candidate_name': candidate_name,
                        'email': candidate_email,
                        'phone': parsed_data.get('candidate_info', {}).get('phone', ''),
                        'match_score': match_score,
                        'anomaly_weight': anomaly_weight,
                        'anomaly_status': shortlist_decision['decision'],
                        'anomaly_severity': anomalies.get('severity', 'none'),
                        'parsed_data': parsed_data,
                        'anomaly_detection': anomalies,
                        'analysis': ats_results if hr_system else {},
                        'file_name': file.filename
                    })
                else:
                    print(f"  ‚ùå REJECTED: {shortlist_decision['reason']}\n")
                    
                    rejected_candidates.append({
                        'candidate_name': candidate_name,
                        'email': candidate_email,
                        'phone': parsed_data.get('candidate_info', {}).get('phone', ''),
                        'anomaly_weight': anomaly_weight,
                        'anomaly_status': shortlist_decision['decision'],
                        'anomaly_severity': anomalies.get('severity', 'high'),
                        'rejection_reason': shortlist_decision['reason'],
                        'recommendation': shortlist_decision['recommendation'],
                        'anomaly_detection': anomalies,
                        'file_name': file.filename
                    })
                
                # Clean up temp file
                if os.path.exists(file_path):
                    os.remove(file_path)
                    
            except Exception as e:
                print(f"  ‚ùå ERROR: {str(e)}\n")
                processing_errors.append({
                    'file_name': file.filename,
                    'error': str(e)
                })
        
        # Rank shortlisted candidates by match score (highest first)
        shortlisted_candidates.sort(key=lambda x: x['match_score'], reverse=True)
        
        # Add rank numbers
        for idx, candidate in enumerate(shortlisted_candidates, 1):
            candidate['rank'] = idx
        
        # Summary
        print(f"\n{'='*70}")
        print(f"üìä SCREENING COMPLETE")
        print(f"{'='*70}")
        print(f"‚úÖ Shortlisted: {len(shortlisted_candidates)}")
        print(f"‚ùå Rejected: {len(rejected_candidates)}")
        print(f"‚ö†Ô∏è  Errors: {len(processing_errors)}")
        print(f"{'='*70}\n")
        
        return jsonify({
            'success': True,
            'data': {
                'total_uploaded': len(files),
                'shortlisted': len(shortlisted_candidates),
                'rejected': len(rejected_candidates),
                'errors': len(processing_errors),
                'anomaly_threshold': anomaly_threshold,
                'shortlisted_candidates': shortlisted_candidates,
                'rejected_candidates': rejected_candidates,
                'processing_errors': processing_errors if processing_errors else None
            }
        })
    
    except Exception as e:
        print(f"Error in bulk resume screening: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/hr/rank-resumes', methods=['POST'])
def hr_rank_resumes():
    """
    HR System: Rank multiple resumes against job description
    DEPRECATED - Use /api/hr/bulk-screen-resumes instead
    """
    try:
        if not hr_system:
            return jsonify({
                'success': False, 
                'error': 'HR System is loading. Please wait a moment and try again.',
                'status': 'loading'
            }), 503
        
        data = request.json
        resume_paths = data.get('resumePaths', [])
        job_description = data.get('jobDescription', '')
        
        if not resume_paths:
            return jsonify({'success': False, 'error': 'Resume paths required'}), 400
        if not job_description:
            return jsonify({'success': False, 'error': 'Job description required'}), 400
        
        # Rank resumes
        rankings = hr_system.rank_resumes(resume_paths, job_description)
        
        # Add rank numbers
        for idx, ranking in enumerate(rankings, 1):
            ranking['rank'] = idx
        
        return jsonify({
            'success': True,
            'data': {
                'rankings': rankings,
                'total_candidates': len(rankings)
            }
        })
    
    except Exception as e:
        print(f"Error in HR rank resumes: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/rank-resumes', methods=['POST'])
def rank_resumes():
    """
    Rank multiple resumes using EXACT HRcode_INTEGRATED.py logic
    
    Request:
    {
        "jobDescription": "...",
        "resumes": [
            {
                "id": "resume_id_1",
                "text": "...",
                "candidateName": "John Doe"
            }
        ]
    }
    
    Response:
    {
        "success": true,
        "data": {
            "rankings": [
                {
                    "rank": 1,
                    "candidateName": "John Doe",
                    "matchScore": 85,
                    "decision": "SHORTLISTED"
                }
            ]
        }
    }
    """
    try:
        data = request.json
        job_description = data.get('jobDescription', '')
        resumes = data.get('resumes', [])
        
        if not job_description:
            return jsonify({'success': False, 'error': 'Job description is required'}), 400
        
        if not resumes or len(resumes) == 0:
            return jsonify({'success': False, 'error': 'At least one resume is required'}), 400
        
        print(f"\n{'='*70}")
        print(f"[RANK-RESUMES] üöÄ RANKING {len(resumes)} RESUMES WITH EXACT HRCODE")
        print(f"{'='*70}")
        
        # Use HRCode service for ranking
        hrcode_svc = get_hrcode_service()
        if not hrcode_svc:
            return jsonify({'success': False, 'error': 'HRCode service not initialized'}), 503
        
        # Prepare resume data for HRCode service
        resume_data_list = [
            {
                'id': r.get('id'),
                'name': r.get('candidateName', 'Unknown'),
                'text': r.get('text', '')
            }
            for r in resumes
        ]
        
        # Use HRCode service to rank all resumes
        rank_result = hrcode_svc.rank_resumes_hrcode(resume_data_list, job_description)
        
        if not rank_result.get('success'):
            return jsonify({
                'success': False,
                'error': rank_result.get('error', 'Ranking failed')
            }), 500
        
        # Transform rankings for API response
        rankings = rank_result.get('rankings', [])
        transformed_rankings = []
        
        for idx, rank in enumerate(rankings, 1):
            transformed_rankings.append({
                'rank': idx,
                'resumeId': rank.get('resumeId'),
                'candidateName': rank.get('candidateName'),
                'matchScore': rank.get('matchScore', 0),
                'anomalyWeight': rank.get('anomalyWeight', 0),
                'anomalySeverity': rank.get('anomalySeverity', 'Low'),
                'decision': rank.get('decision'),
                'reason': rank.get('reason', ''),
                'shortlisted': rank.get('shortlisted', False),
                'matchedSkills': rank.get('matchedSkills', []),
                'missingSkills': rank.get('missingSkills', []),
                'skills': rank.get('skills', []),
                'education': rank.get('education', []),
                'experience': rank.get('experience', []),
                'strengths': [f"‚úì {skill}" for skill in rank.get('matchedSkills', [])[:5]],
                'weaknesses': [f"‚úó {skill}" for skill in rank.get('missingSkills', [])[:3]]
            })
        
        print(f"[RANK-RESUMES] ‚úÖ Ranked {len(transformed_rankings)} resumes successfully")
        print(f"{'='*70}\n")
        
        return jsonify({
            'success': True,
            'data': {
                'rankings': transformed_rankings
            }
        })
    
    except Exception as e:
        print(f"\n‚ùå ERROR in rank-resumes: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/match-jobs', methods=['POST'])
def match_jobs():
    """
    Match resume with jobs and provide recommendations
    
    Request:
    {
        "resumeText": "...",
        "skills": [...],
        "experience": [...],
        "targetRole": "Software Engineer"
    }
    
    Response:
    {
        "success": true,
        "data": {
            "recommendations": [
                {
                    "title": "...",
                    "matchScore": 85,
                    "reasons": [...],
                    "platform": "rozee",
                    "url": "..."
                },
                ...
            ]
        }
    }
    """
    try:
        data = request.json
        resume_text = data.get('resumeText', '')
        skills = data.get('skills', [])
        target_role = data.get('targetRole', '')
        
        if not resume_text and not skills:
            return jsonify({'success': False, 'error': 'Resume text or skills required'}), 400
        
        # Get job recommendations using AI
        recommendations = ai_analyzer.recommend_jobs(resume_text, skills, target_role)
        
        return jsonify({
            'success': True,
            'data': {
                'recommendations': recommendations
            }
        })
    
    except Exception as e:
        print(f"Error matching jobs: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ==================== JOB MATCHING ENDPOINT ====================

@app.route('/api/match-resume-to-jobs', methods=['POST'])
def match_resume_to_jobs():
    """
    POST /api/match-resume-to-jobs
    Score and rank scraped jobs against resume using NLP + semantic matching.

    Request body:
    {
        "resumeSkills": ["Python", "React", "Node.js"],
        "resumeTitle": "Software Engineer",
        "resumeSummary": "Experienced full-stack developer...",
        "resumeExperienceYears": 3,
        "jobs": [ { title, company, location, description, source, url, ... } ],
        "minScore": 30
    }

    Response:
    {
        "success": true,
        "data": {
            "matchedJobs": [ ...scored and ranked... ],
            "statistics": { totalInput, totalMatched, avgScore, topScore }
        }
    }
    """
    try:
        data = request.get_json()
        resume_skills = data.get('resumeSkills', [])
        resume_title = data.get('resumeTitle', '')
        resume_summary = data.get('resumeSummary', '')
        resume_exp = data.get('resumeExperienceYears', 2)
        jobs = data.get('jobs', [])
        min_score = data.get('minScore', 30)

        print(f"\n{'='*60}")
        print(f"AI JOB MATCHING REQUEST")
        print(f"{'='*60}")
        print(f"   Resume Title: {resume_title}")
        print(f"   Skills: {resume_skills[:8]}")
        print(f"   Experience: {resume_exp} years")
        print(f"   Jobs to score: {len(jobs)}")
        print(f"   Min score: {min_score}%")

        if not jobs:
            return jsonify({
                'success': True,
                'data': {
                    'matchedJobs': [],
                    'statistics': {'totalInput': 0, 'totalMatched': 0, 'avgScore': 0, 'topScore': 0}
                }
            })

        if job_matcher:
            matched = job_matcher.match_resume_to_jobs(
                resume_skills=resume_skills,
                resume_title=resume_title,
                resume_summary=resume_summary,
                resume_experience_years=resume_exp,
                jobs=jobs,
                min_score=min_score,
            )
        else:
            # Fallback: simple keyword matching
            print("   [WARN] JobMatcher not available, using basic matching")
            matched = []
            norm_skills = {s.lower() for s in resume_skills}
            for job in jobs:
                job_text = f"{job.get('title', '')} {job.get('description', '')}".lower()
                found = [s for s in resume_skills if s.lower() in job_text]
                score = min(100, 40 + len(found) * 10)
                matched.append({
                    **job,
                    'matchScore': score,
                    'matchedSkills': found,
                    'missingSkills': [],
                })
            matched.sort(key=lambda x: x['matchScore'], reverse=True)
            matched = [j for j in matched if j['matchScore'] >= min_score]

        scores = [j['matchScore'] for j in matched]
        stats = {
            'totalInput': len(jobs),
            'totalMatched': len(matched),
            'avgScore': int(round(sum(scores) / len(scores))) if scores else 0,
            'topScore': max(scores) if scores else 0,
        }

        print(f"\n   Matched: {stats['totalMatched']}/{stats['totalInput']}")
        print(f"   Avg Score: {stats['avgScore']}%")
        print(f"   Top Score: {stats['topScore']}%")
        print(f"{'='*60}\n")

        return jsonify({
            'success': True,
            'data': {
                'matchedJobs': matched,
                'statistics': stats
            }
        })

    except Exception as e:
        print(f"\nMATCH ERROR: {str(e)}")
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


# ==================== JOB API SEARCH ENDPOINTS ====================

@app.route('/api/search-jobs-api', methods=['POST'])
def search_jobs_api():
    """
    POST /api/search-jobs-api
    Search jobs using FREE APIs (Remotive, Jobicy, Arbeitnow, USAJobs)
    
    Request body:
    {
        "query": "Python Developer",
        "location": "Remote",
        "max_per_platform": 10,
        "platforms": ["remotive", "jobicy", "arbeitnow", "usajobs"]  // optional filter
    }
    """
    try:
        print("\n" + "="*60)
        print("JOB API SEARCH REQUEST")
        print("="*60)
        
        data = request.get_json()
        query = data.get('query') or data.get('jobTitle') or data.get('keywords', 'Developer')
        location = data.get('location', '')
        max_per_platform = data.get('max_per_platform', 10)
        platforms = data.get('platforms', ['remotive', 'themuse', 'arbeitnow', 'usajobs'])
        
        print(f"  Query: {query}")
        print(f"  Location: {location}")
        print(f"  Max per platform: {max_per_platform}")
        print(f"  Platforms: {platforms}")
        
        if not job_api_scraper:
            print("  ERROR: Job API Scraper not initialized")
            return jsonify({
                'success': False,
                'error': 'Job API scraper not initialized',
                'data': {'jobs': [], 'jobsByPlatform': {}, 'statistics': {}}
            }), 503
        
        # Search all APIs
        all_jobs = []
        jobs_by_platform = {}
        
        if 'remotive' in platforms:
            remotive_jobs = job_api_scraper.search_remotive(query, location, max_per_platform)
            all_jobs.extend(remotive_jobs)
            jobs_by_platform['remotive'] = remotive_jobs
            print(f"  Remotive: {len(remotive_jobs)} jobs")
        
        if 'jobicy' in platforms or 'themuse' in platforms:
            themuse_jobs = job_api_scraper.search_jobicy(query, location, max_per_platform)
            all_jobs.extend(themuse_jobs)
            jobs_by_platform['themuse'] = themuse_jobs
            print(f"  TheMuse: {len(themuse_jobs)} jobs")
        
        if 'arbeitnow' in platforms:
            arbeitnow_jobs = job_api_scraper.search_arbeitnow(query, location, max_per_platform)
            all_jobs.extend(arbeitnow_jobs)
            jobs_by_platform['arbeitnow'] = arbeitnow_jobs
            print(f"  Arbeitnow: {len(arbeitnow_jobs)} jobs")
        
        if 'usajobs' in platforms:
            usajobs_jobs = job_api_scraper.search_usajobs(query, location, max_per_platform)
            all_jobs.extend(usajobs_jobs)
            jobs_by_platform['usajobs'] = usajobs_jobs
            print(f"  USAJobs: {len(usajobs_jobs)} jobs")
        
        print(f"\n  TOTAL: {len(all_jobs)} jobs from {len(jobs_by_platform)} platforms")
        
        return jsonify({
            'success': True,
            'data': {
                'jobs': all_jobs,
                'jobsByPlatform': jobs_by_platform,
                'statistics': {
                    'total_jobs': len(all_jobs),
                    'platforms_searched': list(jobs_by_platform.keys()),
                    'jobs_per_platform': {k: len(v) for k, v in jobs_by_platform.items()},
                }
            }
        })
        
    except Exception as e:
        print(f"\n  JOB API SEARCH ERROR: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'details': traceback.format_exc()
        }), 500


# ==================== JOB SCRAPING ENDPOINTS ====================

@app.route('/api/scrape-jobs', methods=['POST'])
def scrape_jobs():
    """
    POST /api/scrape-jobs
    Scrape jobs from Indeed Pakistan and Rozee.pk
    Falls back to realistic demo jobs if scraping returns 0 results
    
    Request body:
    {
        "jobTitle": "Python Developer",
        "location": "Karachi",
        "max_results_per_platform": 5
    }
    """
    try:
        print("\n" + "="*60)
        print("üîç JOB SCRAPING REQUEST")
        print("="*60)
        
        data = request.get_json()
        job_title = data.get('jobTitle') or data.get('keywords', 'Developer')
        location = data.get('location', 'Pakistan')
        max_results = data.get('max_results_per_platform', 5)
        
        print(f"üìã Job Title: {job_title}")
        print(f"üìç Location: {location}")
        print(f"üìä Max Results per Platform: {max_results}")
        
        # Check if scraper is available
        if not job_scraper:
            print("‚ùå Job scraper not initialized")
            return jsonify({
                'success': False,
                'error': 'Job scraper initialization failed',
                'data': {'jobs': [], 'jobsByPlatform': {}, 'statistics': {}}
            }), 503
        
        # Perform the scraping
        print("\nüîÑ Starting job search across platforms...")
        results = job_scraper.search_jobs(
            job_title=job_title,
            location=location,
            max_per_platform=max_results
        )
        
        # If no real jobs found, use realistic fallback
        total_jobs = len(results['allJobs'])
        if total_jobs == 0:
            print("\n‚ö†Ô∏è No jobs found from real scraping (sites blocking), using fallback...")
            results = _generate_fallback_jobs(job_title, location, max_results)
            total_jobs = len(results['allJobs'])
            print(f"   Generated {total_jobs} fallback jobs")
        
        print(f"\n‚úÖ Job Search Complete")
        print(f"   Total Jobs: {total_jobs}")
        print(f"   Indeed: {len(results['jobsByPlatform'].get('indeed', []))} jobs")
        print(f"   Rozee: {len(results['jobsByPlatform'].get('rozee', []))} jobs")
        
        return jsonify({
            'success': True,
            'data': {
                'jobs': results['allJobs'],
                'jobsByPlatform': results['jobsByPlatform'],
                'statistics': results['statistics']
            }
        })
        
    except Exception as e:
        print(f"\n‚ùå JOB SCRAPING ERROR: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'details': traceback.format_exc()
        }), 500


def _generate_fallback_jobs(job_title: str, location: str, max_results: int):
    """Generate realistic-looking fallback jobs when real scraping fails"""
    companies = [
        {"name": "TechPakistan Solutions", "source": "indeed"},
        {"name": "Digital Minds Karachi", "source": "rozee"},
        {"name": "CloudBase Technologies", "source": "indeed"},
        {"name": "Innovation Software Labs", "source": "rozee"},
        {"name": "DataSphere Technologies", "source": "indeed"},
        {"name": "WebForce Pakistan", "source": "rozee"},
        {"name": "CodeCraft Solutions", "source": "indeed"},
        {"name": "NextGen Tech Hub", "source": "rozee"},
    ]
    
    jobs = []
    for i in range(min(max_results, len(companies))):
        company = companies[i]
        job = {
            "title": job_title,
            "company": company["name"],
            "location": location,
            "description": f"{job_title} position at {company['name']}. We are looking for experienced professionals.",
            "source": company["source"],
            "url": f"https://{company['source']}.com",
            "posted_date": "Recently"
        }
        jobs.append(job)
    
    # Create by-platform grouping
    indeed_jobs = [j for j in jobs if j['source'] == 'indeed']
    rozee_jobs = [j for j in jobs if j['source'] == 'rozee']
    
    return {
        'allJobs': jobs,
        'jobsByPlatform': {
            'indeed': indeed_jobs,
            'rozee': rozee_jobs
        },
        'statistics': {
            'total_jobs': len(jobs),
            'platforms_scraped': ['indeed', 'rozee'] if jobs else [],
            'jobs_per_platform': {
                'indeed': len(indeed_jobs),
                'rozee': len(rozee_jobs)
            }
        }
    }


if __name__ == '__main__':
    print("=" * 60)
    print("VeriResume Python AI Microservice")
    print("=" * 60)
    print(f"Starting server on http://localhost:5001")
    print(f"OpenAI API Key: {'‚úì Configured' if os.getenv('OPENAI_API_KEY') else '‚úó Not configured'}")
    print(f"Gemini API Key: {'‚úì Configured' if os.getenv('GEMINI_API_KEY') else '‚úó Not configured'}")
    print(f"Groq API Key: {'‚úì Configured' if os.getenv('GROQ_API_KEY') else '‚úó Not configured'}")
    print("=" * 60)
    
    try:
        app.run(host='0.0.0.0', port=5001, debug=False, use_reloader=False, threaded=True)
    except Exception as e:
        print(f"‚ùå Error starting server: {e}")
        import traceback
        traceback.print_exc()
        input("Press Enter to exit...")
